{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Document classification with word embeddings tutorial.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ihab09/CE888/blob/main/text_analytics_labs/lab4_Document_classification_with_word_embeddings_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbVyzKlMCzEL"
      },
      "source": [
        "## Vectors and Topics for Fun\n",
        "### Document classification with Gensim\n",
        "\n",
        "In this tutorial we'll classify movie plots by genre using word embeddings techniques in [gensim](http://radimrehurek.com/gensim/) . \n",
        "\n",
        "See accompanying slides in this repo.\n",
        "\n",
        "We will show how to get a __'hello-world'__ first untuned run using 7 techniques:\n",
        "\n",
        "- Bag of words\n",
        "\n",
        "- Character n-grams\n",
        "\n",
        "- TF-IDF \n",
        "\n",
        "- Averaging word2vec vectors\n",
        "\n",
        "- doc2vec\n",
        "\n",
        "- Deep IR \n",
        "\n",
        "- Word Mover's Distance\n",
        "\n",
        "The goal of this tutorial is to show the API so you can start tuning them yourself. Model tuning of the models is out of scope of this tutorial.\n",
        "\n",
        "We will also compare the accuracy of this first 'no tuning'/out of the box run of these techniques. It is in no way an indication of their best peformance that can be achieved with proper tuning. The benefit of the comparison is to manage the expectations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ae_QGJ1DCzEX"
      },
      "source": [
        "## Requirements\n",
        "- Python 3\n",
        "- [Google News pre-trained word2vec (1.5 GB)](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing)\n",
        "- gensim\n",
        "- sklearn\n",
        "- pandas\n",
        "- matplotlib\n",
        "- nltk with English stopwords\n",
        "- pyemd\n",
        "- 4 GB RAM\n",
        "- 8 GB disk space for WMD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsLO-oliCzEY"
      },
      "source": [
        "## Dataset\n",
        "We will use MovieLens dataset linked with plots from OMDB. Thanks to [Sujit Pal](http://sujitpal.blogspot.de/2016/04/predicting-movie-tags-from-plots-using.html) for this linking idea. The prepared csv is in this repository. If you wish to link the datasets yourself - see the code in the [blog]((http://sujitpal.blogspot.de/2016/04/predicting-movie-tags-from-plots-using.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzytKbcqCzEa",
        "outputId": "ad0e648c-ed11-40a7-a871-2edd518ccb83"
      },
      "source": [
        "import logging\n",
        "logging.root.handlers = []  # Jupyter messes up logging so needs a reset\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "from smart_open import smart_open\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import gensim\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import linear_model\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-08 09:49:21,214 : INFO : 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeSoryo4CzEd"
      },
      "source": [
        "## Exploring the data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "YzmnbxCyCzEf",
        "outputId": "d0e837f7-b5f7-4649-f0c3-af43986803ce"
      },
      "source": [
        "df = pd.read_csv('data/tagged_plots_movielens.csv')\n",
        "df = df.dropna()\n",
        "df['plot'].apply(lambda x: len(x.split(' '))).sum()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bf40ecea20a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/tagged_plots_movielens.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plot'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/tagged_plots_movielens.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTT11HK-CzEi"
      },
      "source": [
        "The dataset is only __170k__ words. It is quite small but makes sure we don't have to wait a long time for the code to complete."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jxG440hCzEk"
      },
      "source": [
        "my_tags = ['sci-fi' , 'action', 'comedy', 'fantasy', 'animation', 'romance']\n",
        "df.tag.value_counts().plot(kind=\"bar\", rot=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmibLk1_CzEn"
      },
      "source": [
        "The data is very unbalanced. We have Comedy as majority class. \n",
        "\n",
        "A naive classifier that predicts everything to be comedy already achieves __40%__ accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVz8-TmjCzEo"
      },
      "source": [
        "The language in sci-fi plots differs a lot from action plots, so there should be some signal here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2owVi7aCzEp"
      },
      "source": [
        "df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5amCz64kCzEt"
      },
      "source": [
        "def print_plot(index):\n",
        "    example = df[df.index == index][['plot', 'tag']].values[0]\n",
        "    if len(example) > 0:\n",
        "        print(example[0])\n",
        "        print('Genre:', example[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAVzQJfKCzEu"
      },
      "source": [
        "print_plot(12)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCSU7wIVCzEu"
      },
      "source": [
        "print_plot(15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGMYTbW-CzEv"
      },
      "source": [
        "Train/test split of 90/10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW-3qq6qCzEw"
      },
      "source": [
        "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmG3eDh4CzEw"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL0hfGKSCzEx"
      },
      "source": [
        "test_data.tag.value_counts().plot(kind=\"bar\", rot=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQDAX639CzEy"
      },
      "source": [
        "## Model evaluation approach\n",
        "We will use confusion matrices to evaluate all classifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GDD7kN7CzEz"
      },
      "source": [
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(my_tags))\n",
        "    target_names = my_tags\n",
        "    plt.xticks(tick_marks, target_names, rotation=45)\n",
        "    plt.yticks(tick_marks, target_names)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NCi05zrCzE0"
      },
      "source": [
        "def evaluate_prediction(predictions, target, title=\"Confusion matrix\"):\n",
        "    print('accuracy %s' % accuracy_score(target, predictions))\n",
        "    cm = confusion_matrix(target, predictions)\n",
        "    print('confusion matrix\\n %s' % cm)\n",
        "    print('(row=expected, col=predicted)')\n",
        "    \n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    plot_confusion_matrix(cm_normalized, title + ' Normalized')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16nlKXTuCzE2"
      },
      "source": [
        "def predict(vectorizer, classifier, data):\n",
        "    data_features = vectorizer.transform(data['plot'])\n",
        "    predictions = classifier.predict(data_features)\n",
        "    target = data['tag']\n",
        "    evaluate_prediction(predictions, target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYyPivhvCzE2"
      },
      "source": [
        "## Baseline: bag of words, n-grams, tf-idf\n",
        "Let's start with some simple baselines before diving into more advanced methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMK7bfwpCzE2"
      },
      "source": [
        "### Bag of words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDMcvezzCzE3"
      },
      "source": [
        "The simplest document feature is just a count of each word occurrence in a document.\n",
        "\n",
        "We remove stop-words and use NLTK tokenizer then limit our vocabulary to 3k most frequent words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaZRQaEPCzE4"
      },
      "source": [
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word.lower())\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDCcRDuQCzE5"
      },
      "source": [
        "%%time\n",
        "# training\n",
        "count_vectorizer = CountVectorizer(\n",
        "    analyzer=\"word\", tokenizer=nltk.word_tokenize,\n",
        "    preprocessor=None, stop_words='english', max_features=3000) \n",
        "\n",
        "train_data_features = count_vectorizer.fit_transform(train_data['plot'])\n",
        "train_data_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1wbm6GKCzE5"
      },
      "source": [
        "Multi-modal logistic regression is a simple white-box classifier. We will use either logistic regression or KNN throughout this tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgIBmw_jCzE7"
      },
      "source": [
        "%%time\n",
        "\n",
        "logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg = logreg.fit(train_data_features, train_data['tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k04aKghCzE8"
      },
      "source": [
        "count_vectorizer.get_feature_names()[80:90]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "any5gq3ZCzE9"
      },
      "source": [
        "Nothing impressive - only 2% better better than the classifier that thinks that everything is a comedy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUkkuSC7CzE9"
      },
      "source": [
        "%%time\n",
        "\n",
        "predict(count_vectorizer, logreg, test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRqgupPRCzE9"
      },
      "source": [
        "White box vectorizer and classifier are great! We can see what are the most important words for sci-fi. This makes it very easy to tune and debug."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te99U3UhCzE-"
      },
      "source": [
        "def most_influential_words(vectorizer, genre_index=0, num_words=10):\n",
        "    features = vectorizer.get_feature_names()\n",
        "    max_coef = sorted(enumerate(logreg.coef_[genre_index]), key=lambda x:x[1], reverse=True)\n",
        "    return [features[x[0]] for x in max_coef[:num_words]]    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeWrOZCrCzE_"
      },
      "source": [
        "# words for the fantasy genre\n",
        "genre_tag_id = 1\n",
        "print(my_tags[genre_tag_id])\n",
        "most_influential_words(count_vectorizer, genre_tag_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szVXhdKSCzE_"
      },
      "source": [
        "train_data_features[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg4tZjN4CzFA"
      },
      "source": [
        "### Character N-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VKstdeKCzFA"
      },
      "source": [
        "A character _n-gram_ is a chunk of a document of length _n_. It is a poor man's tokenizer but sometimes works well. The parameter _n_ depends on language and the corpus. We choose length between 3 and 6 characters and to only focus on 3k most popular ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txG06O0qCzFB"
      },
      "source": [
        "%%time\n",
        "n_gram_vectorizer = CountVectorizer(\n",
        "    analyzer=\"char\",\n",
        "    ngram_range=([2,5]),\n",
        "    tokenizer=None,    \n",
        "    preprocessor=None,                               \n",
        "    max_features=3000) \n",
        "\n",
        "logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
        "\n",
        "train_data_features = n_gram_vectorizer.fit_transform(train_data['plot'])\n",
        "\n",
        "logreg = logreg.fit(train_data_features, train_data['tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-_Q2_h7CzFB"
      },
      "source": [
        "n_gram_vectorizer.get_feature_names()[50:60]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRwIB7gnCzFB"
      },
      "source": [
        "The results are worse than using a tokenizer and bag of words. Probably due to not removing the stop words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCawZqufCzFC"
      },
      "source": [
        "predict(n_gram_vectorizer, logreg, test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl7nAjOVCzFC"
      },
      "source": [
        "### TF-IDF\n",
        "\n",
        "[Term Frequency - Inverse Document Frequency](https://en.wikipedia.org/wiki/Tf%E2%80%93idf) is a little more advanced way to count words in a document.\n",
        "It adjusts for document length, word frequency and most importantly for frequency of a particular word in a particular document.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "-zCRa-bkCzFD"
      },
      "source": [
        "%%time\n",
        "tf_vect = TfidfVectorizer(\n",
        "    min_df=2, tokenizer=nltk.word_tokenize,\n",
        "    preprocessor=None, stop_words='english')\n",
        "train_data_features = tf_vect.fit_transform(train_data['plot'])\n",
        "\n",
        "logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg = logreg.fit(train_data_features, train_data['tag'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp5YXEwFCzFD"
      },
      "source": [
        "tf_vect.get_feature_names()[1000:1010]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tNLIAmTCzFE"
      },
      "source": [
        "predict(tf_vect, logreg, test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSzSvNAACzFG"
      },
      "source": [
        "White box vectorizer and classifier are great! We can see what are the most important words for sci-fi. This makes it very easy to tune and debug."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5a1IVMGCzFI"
      },
      "source": [
        "most_influential_words(tf_vect, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h5jrnW8CzFI"
      },
      "source": [
        "### Things to try with bag of words\n",
        "\n",
        "10 mins for exercises.\n",
        "\n",
        "For more insight into the model print out the most influential words for a particular plot.\n",
        "\n",
        "Try n-grams with TF-IDF.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCpiDeXrCzFJ"
      },
      "source": [
        "# Averaging word vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA5sqPKTCzFK"
      },
      "source": [
        "Now let's use more complex features rather than just counting words.\n",
        "\n",
        "A great recent achievement of NLP is the [word2vec embedding](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf). See Chris Moody's [video](https://www.youtube.com/watch?v=vkfXBGnDplQ) for a great introduction to word2vec. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDzyhj4NCzFL"
      },
      "source": [
        "First we load a word2vec model. It has been pre-trained by Google on a 100 billon word Google News corpus. You can play with this model using a fun [web-app](http://rare-technologies.com/word2vec-tutorial/#app).\n",
        "\n",
        "Link to the web-app: http://rare-technologies.com/word2vec-tutorial/#app\n",
        "\n",
        "Vocabulary size: 3 mln words. \n",
        "\n",
        "__Warning__: 3 mins to load, takes 4 GB of RAM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNq9QBKsCzFL"
      },
      "source": [
        "%%time\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "import os\n",
        "glove2word2vec(glove_input_file=\"data\\\\vectors.50.txt\", word2vec_output_file=\"data\\gensim_glove_vectors.txt\")\n",
        "wv = gensim.models.KeyedVectors.load_word2vec_format( \"data\\gensim_glove_vectors.txt\", binary=False)\n",
        "os.remove('data\\gensim_glove_vectors.txt')\n",
        "wv.init_sims(replace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdWo_dnuCzFM"
      },
      "source": [
        "wv.vector_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwRTYILGCzFM"
      },
      "source": [
        "Example vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErbE-AuXCzFM"
      },
      "source": [
        "from itertools import islice\n",
        "list(islice(wv.vocab, 13000, 13020))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z31bqKCDCzFN"
      },
      "source": [
        "Now we have a vector for each word. How do we get a vector for a sequence of words (aka a document)?\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1yiO-VLCzFO"
      },
      "source": [
        "The most naive way is just to take an average. [Mike Tamir](https://www.youtube.com/watch?v=7gTjYwiaJiU) has suggested that the resulting vector points to a single word summarising the whole document. For example all words in a book\n",
        " ‘A tale of two cities’ should add up to 'class-struggle’"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWq_ewVKCzFP"
      },
      "source": [
        "<img src=\"images/naivedoc2vec.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9a4k5VoCzFP"
      },
      "source": [
        "\n",
        "def word_averaging(wv, words):\n",
        "    all_words, mean = set(), []\n",
        "    \n",
        "    for word in words:\n",
        "        if isinstance(word, np.ndarray):\n",
        "            mean.append(word)\n",
        "        elif word in wv.vocab:\n",
        "            mean.append(wv.syn0norm[wv.vocab[word].index])\n",
        "            all_words.add(wv.vocab[word].index)\n",
        "\n",
        "    if not mean:\n",
        "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
        "        # FIXME: remove these examples in pre-processing\n",
        "        return np.zeros(wv.layer1_size,)\n",
        "\n",
        "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
        "    return mean\n",
        "\n",
        "def  word_averaging_list(wv, text_list):\n",
        "    return np.vstack([word_averaging(wv, review) for review in text_list ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWkKYHg_CzFP"
      },
      "source": [
        "For word2vec we apply a different tokenization. We want to preserve case as the vocabulary distingushes lower and upper case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXadjp3hCzFQ"
      },
      "source": [
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ew9BorlWCzFR"
      },
      "source": [
        "test_tokenized = test_data.apply(lambda r: w2v_tokenize_text(r['plot']), axis=1).values\n",
        "train_tokenized = train_data.apply(lambda r: w2v_tokenize_text(r['plot']), axis=1).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9cELPXqCzFS"
      },
      "source": [
        "%%time\n",
        "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
        "X_test_word_average = word_averaging_list(wv,test_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjegA8F_CzFS"
      },
      "source": [
        "Let's see how KNN and logistic regression classifiers perform on these word-averaging document features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siElPhdhCzFT"
      },
      "source": [
        "%%time\n",
        "knn_naive_dv = KNeighborsClassifier(n_neighbors=3, n_jobs=1, algorithm='brute', metric='cosine' )\n",
        "knn_naive_dv.fit(X_train_word_average, train_data.tag)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2XPXUtWCzFT"
      },
      "source": [
        "%%time\n",
        "predicted = knn_naive_dv.predict(X_test_word_average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMxgUHyECzFU"
      },
      "source": [
        "evaluate_prediction(predicted, test_data.tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i95FaWDuCzFU"
      },
      "source": [
        "KNN is even worse than the naive 'everything is comedy' baseline! Let's see if logistic regression is better."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma0VJNLVCzFW"
      },
      "source": [
        "%%time\n",
        "logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
        "\n",
        "logreg = logreg.fit(X_train_word_average, train_data['tag'])\n",
        "predicted = logreg.predict(X_test_word_average)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEGHg9ECzFX"
      },
      "source": [
        "Great! It gives __54%__ accuracy. Best that we have seen so far."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q49m9sYCzFY"
      },
      "source": [
        "evaluate_prediction(predicted, test_data.tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GHCLi9SCzFZ"
      },
      "source": [
        "Now just for fun let's see if text summarisation works on our data. Let's pick a plot and see which words it averages to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "yG91yfBKCzFZ"
      },
      "source": [
        "test_data.iloc()[56]['plot']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQcEeaOrCzFZ"
      },
      "source": [
        "Hmm... The summarisation doesn't work here. Any ideas why? Hint: look at the area where the average ends up."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNC_ekLgCzFa"
      },
      "source": [
        "wv.most_similar(positive=[X_test_word_average[56]], restrict_vocab=100000, topn=30)[0:20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wFKEc9cCzFb"
      },
      "source": [
        "### Word2vec things to try"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0zffinOCzFb"
      },
      "source": [
        "10 mins exercise\n",
        "\n",
        "Remove stop-words. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTFbdlcWCzFc"
      },
      "source": [
        "\n",
        "\n",
        "def w2v_tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text, language='english'):\n",
        "        for word in nltk.word_tokenize(sent, language='english'):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            if word in stopwords.words('english'):\n",
        "                continue\n",
        "            tokens.append(word)\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nPRtWE9CzFc"
      },
      "source": [
        "### What accuracy do you get?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQPNiU9ZCzFe"
      },
      "source": [
        "### More word2vec things to try\n",
        "\n",
        "Experiment with other pre-trained models - see nice [list](https://github.com/3Top/word2vec-api/) from 3Top.\n",
        "\n",
        "\n",
        "Use Gensim's GloVe converter.\n",
        "\n",
        "\n",
        "Do IDF weighting in the averaging function."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EptSsKluCzFe"
      },
      "source": [
        "# Doc2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb5cYvgsCzFe"
      },
      "source": [
        "A [paper](https://cs.stanford.edu/~quocle/paragraph_vector.pdf) by Google suggests a model for document classification called Paragraph Vectors Doc2Vec or Doc2vec in short. It is very similar to word2vec. \n",
        "\n",
        "It introduces 'a tag' - a word that is in every context in the document.\n",
        "\n",
        "For our first try we tag every plot with its genre. This makes it 'semi-supervised' learning - the genre labels is just one objective among many."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJosf-p5CzFf"
      },
      "source": [
        "from gensim.models import Doc2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-WdqENVCzFg"
      },
      "source": [
        "train_tagged = train_data.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['plot']), tags=[r.tag]), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB7uIIQwCzFg"
      },
      "source": [
        "test_tagged = test_data.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['plot']), tags=[r.tag]), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqk5BBU1CzFh"
      },
      "source": [
        "This is what a training entry looks like - an example plot tagged by 'sci-fi'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4UNg5gNCzFh"
      },
      "source": [
        "test_tagged.values[50]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWdXe8jFCzFi"
      },
      "source": [
        "%%time\n",
        "trainsent = train_tagged.values\n",
        "testsent = test_tagged.values\n",
        "\n",
        "# simple gensim doc2vec api\n",
        "doc2vec_model = Doc2Vec(trainsent, workers=1, size=5, iter=20, dm=1)\n",
        "\n",
        "train_targets, train_regressors = zip(\n",
        "    *[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in trainsent])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz-7K1NBCzFi"
      },
      "source": [
        "Interesting thing about doc2vec is that we need to run gradient descent during prediction to infer the vector for an unseen document. An unseen document is initially assigned a random vector and then this vector fit by gradient descent. Because of this randomness we get different vectors on re-runs of the next cell.\n",
        "\n",
        "Consequently, the accuracy of logistic regression changes when the test set vectors change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgGET2pvCzFj"
      },
      "source": [
        "%%time\n",
        "test_targets, test_regressors = zip(\n",
        "    *[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in testsent])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtnaytc2CzFj"
      },
      "source": [
        "logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg = logreg.fit(train_regressors, train_targets)\n",
        "evaluate_prediction(logreg.predict(test_regressors), test_targets, title=str(doc2vec_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f65inAxHCzFj"
      },
      "source": [
        "KNN gives a lower accuracy than logistic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH5ghzQyCzFk"
      },
      "source": [
        "%%time \n",
        "knn_test_predictions = [\n",
        "    doc2vec_model.docvecs.most_similar([pred_vec], topn=1)[0][0]\n",
        "    for pred_vec in test_regressors\n",
        "]\n",
        "evaluate_prediction(knn_test_predictions, test_targets, str(doc2vec_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2C6wrV3CzFk"
      },
      "source": [
        "Doc2vec gives us a vector for each genre so we can see which genres are close together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmZ9LfeICzFm"
      },
      "source": [
        "doc2vec_model.docvecs.most_similar('action')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDKHgO-bCzFn"
      },
      "source": [
        "Words surrounding the 'sci-fi' tag describe it pretty accurately!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "BcySF7XICzFn"
      },
      "source": [
        "doc2vec_model.most_similar([doc2vec_model.docvecs['sci-fi']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeVIQTgLCzFo"
      },
      "source": [
        "### Doc2vec exercise\n",
        "\n",
        "10 mins\n",
        "\n",
        "Find the random seed that gives the best prediction. :)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3Ct7t95GCzFp"
      },
      "source": [
        "seed = 20\n",
        "\n",
        "doc2vec_model.seed = seed\n",
        "doc2vec_model.random = random.RandomState(seed)\n",
        "\n",
        "\n",
        "test_targets, test_regressors = zip(\n",
        "    *[(doc.tags[0], doc2vec_model.infer_vector(doc.words, steps=20)) for doc in testsent])\n",
        "\n",
        "\n",
        "logreg = linear_model.LogisticRegression(n_jobs=1, C=1e5, random_state=42)\n",
        "logreg = logreg.fit(train_regressors, train_targets)\n",
        "evaluate_prediction(logreg.predict(test_regressors), test_targets, title=str(doc2vec_model))\n",
        "print(doc2vec_model.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvqPekfTCzFr"
      },
      "source": [
        "## Doc2vec things to try\n",
        "Try tagging every sentence with a unique tag 'SENT_123' and then apply KNN. \n",
        "\n",
        "Try multiple tags per plot as in this repo published __today__ : https://github.com/sindbach/doc2vec_pymongo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tK-KRrEmCzFs"
      },
      "source": [
        "# Deep IR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWrWcCzACzFs"
      },
      "source": [
        "'Deep IR' is a technique developed by  [“Document Classification by Inversion of Distributed Language Representations”, Matt Taddy](http://arxiv.org/pdf/1504.07295v3.pdf). Matt has contributed a gensim [tutorial](https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/deepir.ipynb) - great source of more in depth information.\n",
        "\n",
        "In short the algorithm is:\n",
        "\n",
        "1. Train a word2vec model only on comedy plots.\n",
        "\n",
        "2. Trian another model only on sci-fi, another on romance etc. Get 6 models - one for each genre.\n",
        "\n",
        "3. Take a plot and see which model fits it best using Bayes' Theorem\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD8wmYe1CzFt"
      },
      "source": [
        "The tokenization is different from other methods. The reason for this is that we are following an original approach in the paper. The purpose of this tutorial is to see how the models behave out of the box.\n",
        "\n",
        "We just clean non-alphanumeric characters and split by sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzpDmeW0CzFu"
      },
      "source": [
        "import re\n",
        "contractions = re.compile(r\"'|-|\\\"\")\n",
        "# all non alphanumeric\n",
        "symbols = re.compile(r'(\\W+)', re.U)\n",
        "# single character removal\n",
        "singles = re.compile(r'(\\s\\S\\s)', re.I|re.U)\n",
        "# separators (any whitespace)\n",
        "seps = re.compile(r'\\s+')\n",
        "\n",
        "# cleaner (order matters)\n",
        "def clean(text): \n",
        "    text = text.lower()\n",
        "    text = contractions.sub('', text)\n",
        "    text = symbols.sub(r' \\1 ', text)\n",
        "    text = singles.sub(' ', text)\n",
        "    text = seps.sub(' ', text)\n",
        "    return text\n",
        "\n",
        "# sentence splitter\n",
        "alteos = re.compile(r'([!\\?])')\n",
        "def sentences(l):\n",
        "    l = alteos.sub(r' \\1 .', l).rstrip(\"(\\.)*\\n\")\n",
        "    return l.split(\".\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4fP8q6aCzFu"
      },
      "source": [
        "def plots(label):\n",
        "    my_df = None\n",
        "    if label=='training':\n",
        "        my_df = train_data\n",
        "    else:\n",
        "        my_df = test_data\n",
        "    for i, row in my_df.iterrows():\n",
        "        yield {'y':row['tag'],\\\n",
        "        'x':[clean(s).split() for s in sentences(row['plot'])]}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1kHdd5ICzFv"
      },
      "source": [
        "%%time\n",
        "# The corpus is small so can be read into memory\n",
        "revtrain = list(plots(\"training\"))\n",
        "revtest = list(plots(\"test\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppHtY7nMCzFv"
      },
      "source": [
        "# shuffle training set for unbiased word2vec training\n",
        "np.random.shuffle(revtrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0noqpXPTCzFv"
      },
      "source": [
        "def tag_sentences(reviews, stars=my_tags):  \n",
        "    for r in reviews:\n",
        "        if r['y'] in stars:\n",
        "            for s in r['x']:\n",
        "                yield s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e29z5O29CzFv"
      },
      "source": [
        "An example `sci-fi` sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04i0iVaeCzFw"
      },
      "source": [
        "next(tag_sentences(revtrain, my_tags[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAhmaXTECzFx"
      },
      "source": [
        "We train our own 6 word2vec models from scratch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjcLIN_XCzFx"
      },
      "source": [
        "%%time \n",
        "## training\n",
        "from gensim.models import Word2Vec\n",
        "import multiprocessing\n",
        "\n",
        "## create a w2v learner \n",
        "basemodel = Word2Vec(\n",
        "    workers=multiprocessing.cpu_count(), # use your cores\n",
        "    iter=100, # iter = sweeps of SGD through the data; more is better\n",
        "    hs=1, negative=0, # we only have scoring for the hierarchical softmax setup\n",
        "    \n",
        "    )\n",
        "print(basemodel)\n",
        "basemodel.build_vocab(tag_sentences(revtrain)) \n",
        "from copy import deepcopy\n",
        "genremodels = [deepcopy(basemodel) for i in range(len(my_tags))]\n",
        "for i in range(len(my_tags)):\n",
        "    slist = list(tag_sentences(revtrain, my_tags[i]))\n",
        "    print(my_tags[i], \"genre (\", len(slist), \")\")\n",
        "    genremodels[i].train( slist, total_examples=len(slist) ,epochs = basemodel.epochs)\n",
        "# get the probs (note we give docprob a list of lists of words, plus the models)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocpFdLuVCzFy"
      },
      "source": [
        "Now we will compute most likely class for a plot using Bayes' Theorem formula."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQJb27WUCzFy"
      },
      "source": [
        "<img src='images/deep_ir_bayes.png' width=600>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc2TfnonCzFy"
      },
      "source": [
        "For any new sentence we can obtain its _likelihood_ (lhd; actually, the composite likelihood approximation; see the paper) using the [score](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec.score) function in the `word2vec` class.  We get the likelihood for each sentence in the first test review, then convert to a probability over star ratings. Every sentence in the review is evaluated separately and the final star rating of the review is an average vote of all the sentences. This is all in the following handy wrapper. (from the original [tutorial](https://github.com/piskvorky/gensim/blob/develop/docs/notebooks/deepir.ipynb) by Matt Taddy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3r_BD90CzFy"
      },
      "source": [
        "\"\"\"\n",
        "docprob takes two lists\n",
        "* docs: a list of documents, each of which is a list of sentences\n",
        "* models: the candidate word2vec models (each potential class)\n",
        "\n",
        "it returns the array of class probabilities.  Everything is done in-memory.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def docprob(docs, mods):\n",
        "    # score() takes a list [s] of sentences here; could also be a sentence generator\n",
        "    sentlist = [s for d in docs for s in d]\n",
        "    # the log likelihood of each sentence in this review under each w2v representation\n",
        "    llhd = np.array( [ m.score(sentlist, len(sentlist)) for m in mods ] )\n",
        "    # now exponentiate to get likelihoods, \n",
        "    lhd = np.exp(llhd - llhd.max(axis=0)) # subtract row max to avoid numeric overload\n",
        "    # normalize across models (stars) to get sentence-star probabilities\n",
        "    prob = pd.DataFrame( (lhd/lhd.sum(axis=0)).transpose() )\n",
        "    # and finally average the sentence probabilities to get the review probability\n",
        "    prob[\"doc\"] = [i for i,d in enumerate(docs) for s in d]\n",
        "    prob = prob.groupby(\"doc\").mean()\n",
        "    return prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbg3WcVvCzFz"
      },
      "source": [
        "%%time\n",
        "## predict\n",
        "probs = docprob( [r['x'] for r in revtest], genremodels )  \n",
        "predictions = probs.idxmax(axis=1).apply(lambda x: my_tags[x])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PDrji4HCzFz"
      },
      "source": [
        "tag_index = 0\n",
        "col_name = \"out-of-sample prob positive for \" + my_tags[tag_index]\n",
        "probpos = pd.DataFrame({col_name:probs[[tag_index]].sum(axis=1), \n",
        "                        \"true genres\": [r['y'] for r in revtest]})\n",
        "probpos.boxplot(col_name,by=\"true genres\", figsize=(12,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoXFLc_qCzFz"
      },
      "source": [
        "target = [r['y'] for r in revtest]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCnb73ohCzFz"
      },
      "source": [
        "evaluate_prediction(predictions, target, \"Deep IR with word2vec\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KJX6uVSCzF0"
      },
      "source": [
        "Performance is worse than for a naive predictor that says that everything is `comedy`.\n",
        "\n",
        "### Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rlbg1r_KCzF0"
      },
      "source": [
        "\n",
        "\n",
        "It is because we train each word2vec model from scratch on a very small sample of about 30k words.\n",
        "\n",
        "This model needs more data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HoDUbfPCzF0"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCSYAdhZCzF0"
      },
      "source": [
        "Above we shown how to run 'hello-world' in 7 different document classification techniques. It is just a beginning of exploration of their features... There are a lot of parameters that can be tuned to get the best possible results out of them. The 'hello-world' run is in no way an indication of their best peformance. The goal of this tutorial is to show the API so you can start tuning them yourself."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnTqVdMOCzF2"
      },
      "source": [
        "Out of the box \"no tuning\" accuracy of bag of words is not far behind more advanced techniques. \n",
        "Tune them and the pre-processing for them well first and only then reach for more advanced methods if more accuracy is absolutely needed."
      ]
    }
  ]
}